{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prathamesh-Chavan-98/IntelliHire/blob/main/IntelliHire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvcRKWhguw22",
        "outputId": "d2f30b44-9bd3-4bc3-ba7a-395bc36fb2f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: community in /usr/local/lib/python3.11/dist-packages (1.0.0b1)\n",
            "Requirement already satisfied: chroma in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (from community) (3.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask->community) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask->community) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask->community) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask->community) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask->community) (1.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask->community) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement getpass (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for getpass\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain community langchain chroma\n",
        "!pip install openai\n",
        "!pip install getpass\n",
        "!pip install groq\n",
        "!pip install pypdf\n",
        "!pip install pymupdf\n",
        "!pip install python-dotenv\n",
        "!pip install chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install langchain_community\n",
        "from getpass import getpass\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "import fitz\n",
        "from langchain.document_loaders import TextLoader\n",
        "import fitz\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain import hub\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmZLa0OWu7Qv",
        "outputId": "65646ff2-b836-45fe-b208-4ed75c619cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.16)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.32)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# api keys"
      ],
      "metadata": {
        "id": "1tJmiSAkvPV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = userdata.get(\"groq-api-key\")\n",
        "langchain_api_key = userdata.get(\"langchain-api-key\")"
      ],
      "metadata": {
        "id": "XH4cnunsvGEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# connecting with llama"
      ],
      "metadata": {
        "id": "4tZVR87UvcQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "GROQ_API_KEY=groq_api_key\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Retrieve the API key\n",
        "api_key = groq_api_key\n",
        "\n",
        "# Check if the API key is available\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key not found. Set GROQ_API_KEY in the .env file or environment variables.\")\n",
        "\n",
        "# Initialize the Groq client\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "# Send a chat completion request\n",
        "try:\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"hii i am Prathamesh Chavan\",\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "\n",
        "    # Print the response\n",
        "    print(chat_completion.choices[0].message.content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MB6EQiPvGHi",
        "outputId": "dc056886-2bc5-4ef0-98e5-617818c8cb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Prathamesh Chavan! It's nice to meet you! Is there something I can help you with or would you like to chat?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loding the resume"
      ],
      "metadata": {
        "id": "8CllXfeTvs2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PDF document\n",
        "loader = PyPDFLoader(\"/content/PRATHAMESH CHAVAN Resume.pdf\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "8ZJBijflvGKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAzouaa6vGNA",
        "outputId": "8afb72f1-12b0-4356-bef1-ddeb3298d65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/PRATHAMESH CHAVAN Resume.pdf', 'page': 0, 'page_label': '1'}, page_content=\"PRATHAMESH CHAVAN \\n+91-8805702166 | prathamesh.chavan986x@gmail.com  \\nhttps://www.linkedin.com/in/prathamesh-chavan-ml-engineer/       https://github.com/Prathamesh-Chavan-98  \\n \\nI am Prathamesh, an AI/ML enthusiast specializing in Generative AI, LLMs, and MLOps with a strong foundation in Python and \\nData Science. Over the past few years, I have worked on impactful projects, including an AI Interviewer system and an award-\\nwinning Mining Project that secured All India Rank #1 at the SMART INDIA HACKATHON. With expertise in LangChain, \\nTransformers, RAG, and cloud platforms like GCP and Docker, I excel at building intelligent solutions. I am passionate about \\nexploring new domains, quickly mastering concepts, and leveraging cutting-edge technologies to solve real-world problems. \\n \\nEDUCATION  \\nPimpri Chinchwad College of Engineering, Pune, India | Electronics and telecommunication | CGPA: 8                                          2021-25 \\nRajaram College, Kolhapur, India HSC: 79%                                                                                                                                                   2020-21 \\nPrivate Highschool, Kolhapur, India SSC: 91%                                                                                                                                               2018-19 \\n \\nTECHNICAL STACK: Data Analysis, Data Science, Machine Learning, NLP , Generative AI, MLOps, GCP \\nLanguages C, C++ (DSA, OOP), Python, SQL.   \\nLibraries and Frameworks: Pandas, NumPy, SciPy, SkLearn, TensorFlow, Keras, PyTorch, Beastifulsoup, LangChain, Unsloth Git GitHub. \\nDeep Learning: TensorFlow, PyTorch, NLP , Spacy, NLTK, Transformers, Vector Databases, LLM Finetuning, Retrieval Augmented Generation \\n(RAG), Prompt Engineering, Generative AI.  \\nCloud: MLOps, Docker, GCP Services (Vertex AI, BigQuery), Azure. \\n \\nIntelliHire AI Interviewer  \\nFinal Year BTech Project | NLP | LLMs | Hiring Process Automation  \\n• Solved the problem of generic question generation by creating a system that generates personalized, resume-based questions \\ninstead of relying on a predefined question bank.  \\n• Developed an AI Interviewer system enabling businesses to provide requirements and students to submit resumes, GitHub links, \\nand areas of interest.  \\n• Integrated a GitHub code parsing agent and PyPDFLoader to analyze repositories and parse resumes, feeding structured data to \\nan advanced LLM workflow.  \\n• Utilized llama 3.3 70B Versatile for dynamic question generation based on company requirements and candidate inputs.  \\n• Evaluated student responses on a 10-point scale, scoring technical concepts for each question.  \\n• Automated result storage in Excel, enabling efficient candidate ranking and report generation. \\n \\nHYDROMINEX \\nSIH 2023 WINNER #AIR 1 | Image Processing | Autonomous Vehicles | YOLO | AI | Machine Learning  \\n• Designed an intelligent navigation system ensuring seamless vehicle operation in adverse weather by integrating machine learning \\nwith advanced sensor fusion technologies like GPS, Radar and Camera. \\n• Engineered state-of-the-art defogging algorithms and real-time weather forecasting systems, enhancing obstacle detection and \\ncollision prediction with precision. \\n• Developed an AI-powered object detection system using YOLO v8, enabling superior accuracy in identifying and tracking objects \\nunder challenging conditions. \\n• Pioneered innovative AI solutions to mitigate accidents, reduce transit delays, and optimize transportation efficiency in extreme \\nweather scenarios. \\n• Achieved national recognition for impactful contributions to safe and efficient transit systems, setting a benchmark for intelligent \\nmobility solutions. \\n \\nAutomated News Summarization and Analysis:  \\nNLP | Web Scrapping | NLTK  \\n• Engineered an automated news summarization and analysis tool that extracts key points from an average of 1000 news articles \\nweekly and provides sentiment analysis summaries in 150 words.  \\n• Utilized Hugging Face's Transformers for summarization and NLTK for text processing. Aided in quickly digesting large volumes of \\nnews content through advanced NLP techniques   \\n• Employed NLTK for text preprocessing, including tokenization, stop-words removal, stemming, and lemmatization, to enhance data \\nquality and ensure more accurate summarization and sentiment analysis. \")]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# docs formatting"
      ],
      "metadata": {
        "id": "SGy9ifFgwCkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to format documents\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Function to generate a response using RAG\n",
        "def generate_rag_response(question):\n",
        "    # Retrieve relevant documents\n",
        "    relevant_docs = retriever.get_relevant_documents(question)\n",
        "\n",
        "    if not relevant_docs:\n",
        "        return \"No relevant documents found.\"\n",
        "\n",
        "    # Format the retrieved documents as context\n",
        "    context = format_docs(relevant_docs)\n",
        "\n",
        "    # Fill the prompt with retrieved context and the question\n",
        "    formatted_prompt = prompt.format(context=context, question=question)\n",
        "\n",
        "    # Get the response from the LLM\n",
        "    response = get_groq_response(formatted_prompt)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "yE5S52d_vGPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting groq response for llm"
      ],
      "metadata": {
        "id": "TlR-llSnwIDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_groq_response(prompt, llm_name=\"llama-3.3-70b-versatile\"):\n",
        "    \"\"\"\n",
        "    Gets a response from the Groq API.\n",
        "\n",
        "    Args:\n",
        "        prompt: The prompt to send to the API.\n",
        "        llm_name: The name of the LLM to use.\n",
        "\n",
        "    Returns:\n",
        "        The response from the API.\n",
        "    \"\"\"\n",
        "    # Access the groq_api_key from the global scope\n",
        "    global groq_api_key\n",
        "\n",
        "    client = Groq(\n",
        "        api_key=groq_api_key,\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"you are a helpful assistant.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=llm_name,\n",
        "    )\n",
        "\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "dICp0VCdvGSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inputs from user"
      ],
      "metadata": {
        "id": "TvTXmayywQZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect user input about their skills and area of interest\n",
        "user_skills = input(\"Enter your skills (comma-separated): \").strip().split(',')\n",
        "user_area_of_interest = input(\"Enter your area of interest: \").strip()\n",
        "\n",
        "print(f\"\\nSkills: {user_skills}\")\n",
        "print(f\"Area of Interest: {user_area_of_interest}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mowjDKcZvGVh",
        "outputId": "c65bdb0c-d819-4205-d51e-d6fd0d50bc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your skills (comma-separated): data science\n",
            "Enter your area of interest: machine learning\n",
            "\n",
            "Skills: ['data science']\n",
            "Area of Interest: machine learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Generation"
      ],
      "metadata": {
        "id": "2zn7awurwi8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all input data into a query prompt\n",
        "def generate_relevant_questions():\n",
        "    question_prompt = f\"\"\"\n",
        "\n",
        "    - Resume Content: {docs}\n",
        "    - Skills: {user_skills}\n",
        "    - Area of Interest: {user_area_of_interest}\n",
        "\n",
        "    You are a professional AI interviewer tasked with generating **10 highly relevant, realistic, and knowledge-assessing** interview questions based on a candidate's resume, projects, skills, and areas of interest.\n",
        "ask questions on Resume Content: {docs}\n",
        "ask questions on Skills: {user_skills}\n",
        " ask questions on Area of Interest: {user_area_of_interest}\n",
        "\n",
        "    generate moderate level questions on project keep the language of questions easy include project name if available while asking questions\n",
        "    ask each question on each project dont focus on only one project\n",
        "    strictly generate only questions and no other word that pure questions\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the response and extract content as string\n",
        "    response = get_groq_response(question_prompt)\n",
        "    return response  # Access the content attribute of AIMessage\n",
        "\n",
        "# Generate and display questions\n",
        "questions = generate_relevant_questions()\n",
        "\n",
        "# Print the generated questions\n",
        "print(\"\\nTop 10 Relevant Questions:\")\n",
        "for idx, question in enumerate(questions.split('\\n'), 1):\n",
        "    print(f\"{idx}. {question}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soMM3dcgvGdh",
        "outputId": "43b6deed-e3cb-4e0e-9a14-f3a34a1303b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Relevant Questions:\n",
            "1. What inspired you to work on the IntelliHire AI Interviewer project and how did you come up with the idea of generating personalized resume-based questions?\n",
            "2. How did you utilize the LangChain and Transformers libraries in the IntelliHire AI Interviewer project to improve the accuracy of the question generation process?\n",
            "3. What were some of the challenges you faced while integrating the GitHub code parsing agent and PyPDFLoader in the IntelliHire AI Interviewer project?\n",
            "4. Can you explain the process of evaluating student responses in the IntelliHire AI Interviewer project and how you scored technical concepts for each question?\n",
            "5. How did you utilize the llama 3.3 70B Versatile model in the IntelliHire AI Interviewer project for dynamic question generation based on company requirements and candidate inputs?\n",
            "6. What role did data science play in the development of the HYDROMINEX project and how did you apply machine learning concepts to it?\n",
            "7. How did you design the intelligent navigation system in the HYDROMINEX project to ensure seamless vehicle operation in adverse weather conditions?\n",
            "8. What were some of the techniques you used to optimize the object detection system in the HYDROMINEX project to achieve superior accuracy in identifying and tracking objects?\n",
            "9. Can you describe the process of engineering state-of-the-art defogging algorithms and real-time weather forecasting systems in the HYDROMINEX project?\n",
            "10. How did you employ NLP techniques in the Automated News Summarization and Analysis project to extract key points from large volumes of news articles?\n",
            "11. What was the role of NLTK in the Automated News Summarization and Analysis project and how did you utilize it for text preprocessing and sentiment analysis?\n",
            "12. How did you apply machine learning concepts in the Automated News Summarization and Analysis project to provide accurate summarization and sentiment analysis summaries?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accepting and Judging Answers**"
      ],
      "metadata": {
        "id": "qPzjHtto_dXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate relevant questions based on resume, skills, and area of interest\n",
        "def generate_relevant_questions(docs, user_skills, user_area_of_interest):\n",
        "    question_prompt = f\"\"\"\n",
        "    - Resume Content: {docs}\n",
        "    - Skills: {user_skills}\n",
        "    - Area of Interest: {user_area_of_interest}\n",
        "\n",
        "    You are a professional AI interviewer tasked with generating **10 highly relevant, realistic, and knowledge-assessing** interview questions based on a candidate's resume, projects, skills, and areas of interest.\n",
        "    Ask questions on Resume Content: {docs}\n",
        "    Ask questions on Skills: {user_skills}\n",
        "    Ask questions on Area of Interest: {user_area_of_interest}\n",
        "\n",
        "    Generate moderate level questions on the project, keep the language of questions easy, and include the project name if available while asking questions.\n",
        "    Ask each question on each project. Do not focus on only one project.\n",
        "    Strictly generate only questions and no other word, only pure questions.\n",
        "    \"\"\"\n",
        "\n",
        "    # Assuming get_groq_response is defined elsewhere to interact with the LLM (like Groq or others)\n",
        "    response = get_groq_response(question_prompt)\n",
        "    return response.split(\"\\n\")  # Split the response into individual questions\n",
        "\n",
        "# Function to interactively get answers from the user\n",
        "def interactive_questionnaire(questions):\n",
        "    answers = []  # Store the answers\n",
        "    print(\"Interactive Q&A Session:\\n\")\n",
        "    for idx, question in enumerate(questions, 1):\n",
        "        question = question.strip()  # Clean up any whitespace\n",
        "        if question:  # Ignore empty lines\n",
        "            print(f\"Question {idx}: {question}\")  # Display the question\n",
        "            answer = input(\"Your Answer: \")  # Get the user's answer\n",
        "            answers.append((question, answer))  # Store the question-answer pair\n",
        "            print()  # Add spacing for better readability\n",
        "    return answers\n",
        "\n",
        "# Function to evaluate answers using LLM (Groq or similar)\n",
        "def judge_answers_groq(qa_pairs):\n",
        "    scored_responses = []  # List to store scored evaluations\n",
        "\n",
        "    for idx, (question, answer) in enumerate(qa_pairs, 1):\n",
        "        # Create the judging prompt\n",
        "        judging_prompt = f\"\"\"\n",
        "        Evaluate the candidate's response to the following question based on relevance, clarity, and correctness.\n",
        "        Strictly judge the answer for core concepts, depth of understanding, and conciseness.\n",
        "        Provide a score out of 10 (whole number only).\n",
        "\n",
        "        Question: {question}\n",
        "        Answer: {answer}\n",
        "\n",
        "        Your evaluation should be in this format:\n",
        "        - Score: <score out of 10>\n",
        "        - Justification: <reasoning>\n",
        "        \"\"\"\n",
        "\n",
        "        # Assuming `client.chat.completions.create` is defined elsewhere for LLM integration (like Groq or others)\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": judging_prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\"\n",
        "        )\n",
        "\n",
        "        # Extract the response content\n",
        "        evaluation = chat_completion.choices[0].message.content.strip()\n",
        "        scored_responses.append((question, answer, evaluation))\n",
        "\n",
        "    return scored_responses\n",
        "\n",
        "\n",
        "# Generate the list of questions from the candidate's information\n",
        "questions = generate_relevant_questions(docs, user_skills, user_area_of_interest)\n",
        "\n",
        "# Interactive function to display questions and capture answers sequentially\n",
        "answers = interactive_questionnaire(questions)\n",
        "\n",
        "# Now, evaluate the answers using Groq LLM\n",
        "judged_results = judge_answers_groq(answers)\n",
        "\n",
        "# Display the results (scoring and justifications)\n",
        "print(\"\\nEvaluation Results:\\n\")\n",
        "for idx, (question, answer, evaluation) in enumerate(judged_results, 1):\n",
        "    print(f\"Q{idx}: {question}\")\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(f\"Evaluation:\\n{evaluation}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQfggoikvGl9",
        "outputId": "cbd0ed15-2112-44d0-ccc7-aeb661dd550d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive Q&A Session:\n",
            "\n",
            "Question 1: What inspired you to work on the IntelliHire AI Interviewer project and how did you come up with the idea of generating personalized resume-based questions?\n",
            "Your Answer: a\n",
            "\n",
            "Question 2: How did you integrate machine learning with sensor fusion technologies like GPS, Radar, and Camera in the HYDROMINEX project to ensure seamless vehicle operation in adverse weather?\n",
            "Your Answer: a\n",
            "\n",
            "Question 3: What role did Natural Language Processing play in your Automated News Summarization and Analysis project, and how did you utilize NLTK for text processing?\n",
            "Your Answer: a\n",
            "\n",
            "Question 4: Can you explain the process of developing an AI-powered object detection system using YOLO v8 in the HYDROMINEX project, and how it helped in identifying and tracking objects under challenging conditions?\n",
            "Your Answer: a\n",
            "\n",
            "Question 5: How did you utilize LangChain, Transformers, and RAG in your projects, and what benefits did you see in using these technologies?\n",
            "Your Answer: a\n",
            "\n",
            "Question 6: What was the most challenging part of working on the IntelliHire AI Interviewer project, and how did you overcome the challenges of dynamic question generation based on company requirements and candidate inputs?\n",
            "Your Answer: a\n",
            "\n",
            "Question 7: How did you evaluate the performance of your Automated News Summarization and Analysis tool, and what metrics did you use to measure its effectiveness?\n",
            "Your Answer: a\n",
            "\n",
            "Question 8: What were some of the key lessons you learned from working on the HYDROMINEX project, and how did you apply those lessons to other projects like IntelliHire AI Interviewer?\n",
            "Your Answer: a\n",
            "\n",
            "Question 9: Can you walk us through your process of engineering state-of-the-art defogging algorithms and real-time weather forecasting systems in the HYDROMINEX project, and how they enhanced obstacle detection and collision prediction?\n",
            "Your Answer: a\n",
            "\n",
            "Question 10: How do you see your work on projects like IntelliHire AI Interviewer and HYDROMINEX contributing to the broader field of machine learning and data science, and what potential impact do you think they could have on industry and society?\n",
            "Your Answer: a\n",
            "\n",
            "\n",
            "Evaluation Results:\n",
            "\n",
            "Q1: What inspired you to work on the IntelliHire AI Interviewer project and how did you come up with the idea of generating personalized resume-based questions?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response is completely irrelevant and lacks any substance, as it only contains a single letter \"a\" without providing any meaningful information or explanation regarding the IntelliHire AI Interviewer project or the idea of generating personalized resume-based questions. This response does not demonstrate any understanding of the core concepts or provide any conciseness, clarity, or correctness in addressing the question.\n",
            "\n",
            "Q2: How did you integrate machine learning with sensor fusion technologies like GPS, Radar, and Camera in the HYDROMINEX project to ensure seamless vehicle operation in adverse weather?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided is \"a\", which lacks any relevance, clarity, or correctness in addressing the question about integrating machine learning with sensor fusion technologies in the HYDROMINEX project. It does not demonstrate any understanding of the core concepts involved, such as machine learning, sensor fusion, or the challenges of operating vehicles in adverse weather. The response is also extremely concise to the point of being non-informative, failing to provide any depth of understanding or meaningful insight into the project or technologies mentioned.\n",
            "\n",
            "Q3: What role did Natural Language Processing play in your Automated News Summarization and Analysis project, and how did you utilize NLTK for text processing?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided is \"a\", which lacks any relevance, clarity, or correctness in addressing the question about the role of Natural Language Processing (NLP) in the Automated News Summarization and Analysis project and the utilization of NLTK for text processing. It does not demonstrate any understanding of core concepts related to NLP, NLTK, or text processing, and it fails to provide a concise or meaningful explanation. A satisfactory answer should have discussed how NLP was applied in the project, specifically how NLTK was used for tasks such as tokenization, stemming, tagging, or parsing, and how these contributed to the summarization and analysis of news.\n",
            "\n",
            "Q4: Can you explain the process of developing an AI-powered object detection system using YOLO v8 in the HYDROMINEX project, and how it helped in identifying and tracking objects under challenging conditions?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response, \"a\", is completely irrelevant and lacks any clarity or correctness. It does not address the question about the process of developing an AI-powered object detection system using YOLO v8 in the HYDROMINEX project or how it helped in identifying and tracking objects under challenging conditions. The response does not demonstrate any understanding of the core concepts related to YOLO v8, object detection, or the project's challenges. It is concise but entirely uninformative, warranting a score of 0.\n",
            "\n",
            "Q5: How did you utilize LangChain, Transformers, and RAG in your projects, and what benefits did you see in using these technologies?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided, \"a\", does not address the question in any meaningful way. It lacks relevance, clarity, and correctness, failing to demonstrate any understanding of LangChain, Transformers, and RAG, or how these technologies were utilized in projects. There is no core concept discussed, no depth of understanding shown, and the response is not concise but rather non-existent in terms of providing useful information.\n",
            "\n",
            "Q6: What was the most challenging part of working on the IntelliHire AI Interviewer project, and how did you overcome the challenges of dynamic question generation based on company requirements and candidate inputs?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided is \"a\", which is not relevant, clear, or correct in the context of the question. The question asks for the most challenging part of working on a specific project and how the candidate overcame challenges related to dynamic question generation. The response does not address the question at all, failing to demonstrate any understanding of the project, the challenges faced, or the strategies used to overcome them. Therefore, the answer lacks all core concepts, depth of understanding, and conciseness required for a meaningful response.\n",
            "\n",
            "Q7: How did you evaluate the performance of your Automated News Summarization and Analysis tool, and what metrics did you use to measure its effectiveness?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response, \"a\", does not provide any relevant information regarding the evaluation of the Automated News Summarization and Analysis tool. It lacks clarity, correctness, and depth of understanding, failing to mention any metrics or methods used to measure the tool's effectiveness. A satisfactory answer would require a detailed explanation of the evaluation process and the metrics used, such as precision, recall, F1 score, ROUGE score, or other relevant performance indicators. The response given does not meet these expectations.\n",
            "\n",
            "Q8: What were some of the key lessons you learned from working on the HYDROMINEX project, and how did you apply those lessons to other projects like IntelliHire AI Interviewer?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response is not provided, making it impossible to evaluate their answer based on relevance, clarity, correctness, core concepts, depth of understanding, and conciseness. Without a response, there is no basis for assessment.\n",
            "\n",
            "Q9: Can you walk us through your process of engineering state-of-the-art defogging algorithms and real-time weather forecasting systems in the HYDROMINEX project, and how they enhanced obstacle detection and collision prediction?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response, \"a\", is completely irrelevant, unclear, and incorrect. It does not address the question about the process of engineering defogging algorithms and real-time weather forecasting systems in the HYDROMINEX project, nor does it provide any information on how these systems enhanced obstacle detection and collision prediction. The response lacks any core concepts, depth of understanding, and conciseness, failing to demonstrate even a basic understanding of the topic.\n",
            "\n",
            "Q10: How do you see your work on projects like IntelliHire AI Interviewer and HYDROMINEX contributing to the broader field of machine learning and data science, and what potential impact do you think they could have on industry and society?\n",
            "Answer: a\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided is \"a\", which is not a coherent or meaningful response to the question. It lacks relevance, clarity, and correctness, failing to address the core concepts of how the projects contribute to the broader field of machine learning and data science, or their potential impact on industry and society. The response does not demonstrate any depth of understanding or conciseness, as it is essentially a blank answer. A proper evaluation of the candidate's understanding and vision for the projects' contributions and impacts cannot be made based on this response.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Storing in Excel**"
      ],
      "metadata": {
        "id": "HoKGuuEM_jjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to store scores in an Excel file\n",
        "def store_scores_in_excel(judged_results, filename=\"evaluation_scores.xlsx\"):\n",
        "    # Extract question, answer, and score from judged results\n",
        "    data = [(question, answer, int(evaluation.split(\"\\n\")[0].split(\":\")[1].strip()))\n",
        "            for question, answer, evaluation in judged_results]\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data, columns=[\"Question\", \"Answer\", \"Score\"])\n",
        "\n",
        "    # Write the DataFrame to an Excel file\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"Scores have been saved to {filename}\")\n",
        "\n",
        "# Example: Store the evaluated scores from the judge_answers_groq function\n",
        "store_scores_in_excel(judged_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8It7P-qvGov",
        "outputId": "a55f53c3-489e-4a10-e2c3-37c8fb90f50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores have been saved to evaluation_scores.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to store scores in an Excel file and include the total sum of scores\n",
        "def store_scores_in_excel(judged_results, filename=\"evaluation_scores.xlsx\"):\n",
        "    # Extract question, answer, and score from judged results\n",
        "    data = [(question, answer, int(evaluation.split(\"\\n\")[0].split(\":\")[1].strip()))\n",
        "            for question, answer, evaluation in judged_results]\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data, columns=[\"Question\", \"Answer\", \"Score\"])\n",
        "\n",
        "    # Sum the scores\n",
        "    total_score = df[\"Score\"].sum()\n",
        "\n",
        "    # Append total score to the DataFrame as a new row\n",
        "    total_row = pd.DataFrame([[\"Total\", \"\", total_score]], columns=[\"Question\", \"Answer\", \"Score\"])\n",
        "    df = pd.concat([df, total_row], ignore_index=True)\n",
        "\n",
        "    # Write the DataFrame to an Excel file\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"Scores and total score have been saved to {filename}\")\n",
        "\n",
        "# Example: Store the evaluated scores from the judge_answers_groq function\n",
        "store_scores_in_excel(judged_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6P1gLNZvGu4",
        "outputId": "5048d2a9-b109-4ae1-8bb9-889062a9de5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores and total score have been saved to evaluation_scores.xlsx\n"
          ]
        }
      ]
    }
  ]
}